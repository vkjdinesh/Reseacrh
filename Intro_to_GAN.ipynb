{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjdinesh/Reseacrh/blob/main/Intro_to_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze2rpVHSkt4U"
      },
      "source": [
        "# Digit generation using Deep Convolution GANs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRl7sIPUE1Fb"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3mx6ebbMM6L"
      },
      "source": [
        "Instructions: \n",
        "* Make sure the runtime is set to GPU.\n",
        "* If you want to clear all outputs you can go to Edit -> Clear all outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B6K7FLKppmY"
      },
      "source": [
        "## 1. Import libraries and load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFsdxIAvm_8a"
      },
      "source": [
        "### 1.0 Installing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IugzN1-ZOO4Z"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRUOkjiupfKC"
      },
      "source": [
        "### 1.1 Importing the required libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33bXA8PHnqBR"
      },
      "source": [
        "We will download and extreact the assets folder that contains utils.py file and some gif file for visual representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRod9RoYizc6"
      },
      "source": [
        "import gdown\n",
        "url = 'https://drive.google.com/uc?export=download&id=1NueLFReJ0BClJzjPoi3vVkVlB1PfkJJn'\n",
        "output = 'Assets.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE3cTYjtkSb1"
      },
      "source": [
        "!unzip /content/Assets.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfwrCJ9WkouW"
      },
      "source": [
        "from IPython import display\n",
        "from utils import Logger\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0YPE26gks71"
      },
      "source": [
        "### 1.2 Loading and transforming the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUOiCBDRqJ56"
      },
      "source": [
        "DATA_FOLDER = './torch_data/DCGAN/MNIST'\n",
        "'''\n",
        "The normalize function will normalize the image in the range [-1,1]. \n",
        "For example, the minimum value 0 will be converted to (0-0.5)/0.5=-1, and \n",
        "the maximum value of 1 will be converted to (1-0.5)/0.5=1.\n",
        "'''\n",
        "def mnist_data():\n",
        "    # We resize the image, convert them to tensors and normalize our image values to be between -1 and 1\n",
        "    compose = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(64),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((.5,), (.5,)) #Can refer https://discuss.pytorch.org/t/understanding-transform-normalize/21730 for more info\n",
        "        ])\n",
        "    out_dir = '{}/dataset'.format(DATA_FOLDER)\n",
        "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-wV_RFLrnvp"
      },
      "source": [
        "data = mnist_data()\n",
        "batch_size = 100  #can change to lower values if needed default: 100\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn5NFD3uK9kV"
      },
      "source": [
        "MNIST Data Sample:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJVBdf0GKyQ_"
      },
      "source": [
        "![Train Data MNIST Sample](https://drive.google.com/uc?export=view&id=1iy7j2gIRaoFcL-nQV99PtQOeoPOo-sxN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5shjlGwGEycr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2LPBjh0sUZY"
      },
      "source": [
        "## 2. Create(define) the Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siw0Qq-gFhI_"
      },
      "source": [
        "![GAN Structure](https://drive.google.com/uc?export=view&id=1iCSX8g4EqB2dHe-_rlsBBl8FSKt5IufY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_FDjaqMsjFR"
      },
      "source": [
        "### 2.1 Generator Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFN8yk0UspOm"
      },
      "source": [
        "class GenerativeNet(torch.nn.Module):\n",
        "    #Defining the constructor\n",
        "    def __init__(self):\n",
        "        super(GenerativeNet, self).__init__()\n",
        "        # Fully connected layer that takes in the generated noise\n",
        "        self.linear = torch.nn.Linear(100, 1024*4*4)\n",
        "        #First ConvTranspose layer\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        #Second ConvTranspose layer\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        #Third ConvTranspose layer\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        #Fourth ConvTranspose layer\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=128, out_channels=1, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        )\n",
        "        #Apply tanh to get outputs in the range (-1,1)\n",
        "        self.out = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Project and reshape\n",
        "        x = self.linear(x)\n",
        "        x = x.view(x.shape[0], 1024, 4, 4)\n",
        "        # Apply ConvTranspose layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        # Apply Tanh\n",
        "        return self.out(x)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFYoEXfruSkQ"
      },
      "source": [
        "# Noise creator using random numbers\n",
        "def noise(size):\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    if torch.cuda.is_available(): return n.cuda()\n",
        "    return n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9F2z8yUu9BQ"
      },
      "source": [
        "### 2.2 Discriminator Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6xDVbn7vBLA"
      },
      "source": [
        "class DiscriminativeNet(torch.nn.Module):\n",
        "    #Defining the constructor\n",
        "    def __init__(self):\n",
        "        super(DiscriminativeNet, self).__init__()\n",
        "        #First Conv layer\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        #Second Conv layer\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        #Third Conv layer\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        #Fourth Conv layer\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        #Apply the Fullyconnected layer and then sigmoid\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024*4*4, 1),\n",
        "            #Apply sigmoid to get outputs in the range (0,1)\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply Convolutional layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        # Flatten and apply sigmoid\n",
        "        x = x.view(-1, 1024*4*4)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWwE_dKFyINp"
      },
      "source": [
        "### 2.3 Initialize weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZFaLIGUyNWQ"
      },
      "source": [
        "def init_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 or classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(0.00, 0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnbToHa_yZMP"
      },
      "source": [
        "### 2.4 Create the instance of Network Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faNmks4XyYNi"
      },
      "source": [
        "# Create Network instances and init weights\n",
        "generator = GenerativeNet()\n",
        "generator.apply(init_weights)\n",
        "\n",
        "discriminator = DiscriminativeNet()\n",
        "discriminator.apply(init_weights)\n",
        "\n",
        "# Enable cuda if available to train faster using a GPU\n",
        "if torch.cuda.is_available():\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hux9VslGzzN5"
      },
      "source": [
        "### 2.5 Visualize the model using summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__xKYa7Ez6Ko"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "#Summary for generator\n",
        "summary(generator, input_size=(100,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCVhOdmG0JRq"
      },
      "source": [
        "#Summary for discriminator\n",
        "summary(discriminator, input_size=(1, 64, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp9vp4qVEtzu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCJEdeYq5BwZ"
      },
      "source": [
        "# 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0KUEg3_1wNqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "319rT1gY0uwf"
      },
      "source": [
        "### 3.1 Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tJqnV2Z0zee"
      },
      "source": [
        "# Optimizers\n",
        "d_optimizer = Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "g_optimizer = Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Loss function\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 1 #Change to a larger number if needed after hands-on training default value: 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ_5SfK15KKY"
      },
      "source": [
        "### 3.2 Create target data (labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCzBADeO5ROm"
      },
      "source": [
        "#Real data's label will have value = 1 (for discriminator to show it's a true image)\n",
        "def real_data_target(size):\n",
        "    #Tensor containing ones, with shape = size [1,1,1,....,1]\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    if torch.cuda.is_available(): return data.cuda()\n",
        "    return data\n",
        "    \n",
        "#Fake data's label will have value = 0 (for discriminator to show it's a generated image)\n",
        "def fake_data_target(size):\n",
        "    #Tensor containing zeros, with shape = size [0,0,0....,0]\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    if torch.cuda.is_available(): return data.cuda()\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLFjiZg86Mpp"
      },
      "source": [
        "### 3.3 Encapsulating train functions for generator and discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HjV0KN56MI6"
      },
      "source": [
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1. Train on Real Data\n",
        "    prediction_real = discriminator(real_data)\n",
        "    # Calculate error by comparing real with 1's and backpropagate\n",
        "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
        "    error_real.backward()\n",
        "\n",
        "    # 2. Train on Fake Data\n",
        "    prediction_fake = discriminator(fake_data)\n",
        "    # Calculate error by comparing fake with 0's and backpropagate\n",
        "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
        "    error_fake.backward()\n",
        "    \n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    return error_real + error_fake, prediction_real, prediction_fake\n",
        "    return (0, 0, 0)\n",
        "\n",
        "\n",
        "def train_generator(optimizer, fake_data):\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
        "    error.backward()\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCTtMmPgAlkR"
      },
      "source": [
        "### 3.4 Generate samples for testing using noise function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frnMJhn6Ak2a"
      },
      "source": [
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn5V5AY1A2Ai"
      },
      "source": [
        "### 3.5 Train the model and log the results after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFs_aB086Lsy"
      },
      "source": [
        "logger = Logger(model_name='DCGAN', data_name='MNIST')\n",
        "cond = False\n",
        "gen_loss_list = []\n",
        "disc_loss_list = []\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "        \n",
        "        # 1. Train Discriminator\n",
        "        real_data = Variable(real_batch)\n",
        "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_data.size(0))).detach()\n",
        "        # Run Train Discriminator function\n",
        "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer, real_data, fake_data)\n",
        "        disc_loss_list.append(d_error.item())\n",
        "\n",
        "        # 2. Train Generator\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_batch.size(0)))\n",
        "        # Run Train Generator function\n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "        gen_loss_list.append(g_error.item())\n",
        "        # Log error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "        \n",
        "        # Display Progress\n",
        "        if (n_batch) % 100 == 0:\n",
        "            #Uncomment the line below to only see the latest iteration output\n",
        "            #display.clear_output(True) \n",
        "            # Display Images\n",
        "            test_images = generator(test_noise).data.cpu()\n",
        "            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )\n",
        "\n",
        "            #For plotting the disc error and gen error graph\n",
        "            if cond:\n",
        "              step_bins = 20\n",
        "              x_axis = sorted([i * step_bins for i in range(len(gen_loss_list) // step_bins)] * step_bins)\n",
        "              sns.lineplot(x_axis, gen_loss_list[:len(x_axis)], label=\"Generator's Loss\")\n",
        "              sns.lineplot(x_axis, disc_loss_list[:len(x_axis)], label=\"Discriminator's Loss\")\n",
        "              plt.legend()\n",
        "              plt.ylim(min(min(disc_loss_list[-100:]), min(gen_loss_list[-100:])), \n",
        "                       max(max(disc_loss_list[-100:]), max(gen_loss_list[-100:])))\n",
        "              plt.show()\n",
        "            cond = True\n",
        "        # Model Checkpoints\n",
        "        logger.save_models(generator, discriminator, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcUfy9lGIr1s"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Kw5olPImIW"
      },
      "source": [
        "# 4. Results after training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iAuiEqaIt08"
      },
      "source": [
        "Epoch 0:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y37D6JEDHKGf"
      },
      "source": [
        "![Epoch_0](https://drive.google.com/uc?export=view&id=1bAoQhSMhKpx2Dr1FW0PpfjZ92mqaoulx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XVniwnnIwK8"
      },
      "source": [
        "Epoch 10:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELtH8kaBIy3E"
      },
      "source": [
        "![Epoch_10](https://drive.google.com/uc?export=view&id=1K4Su633DlbqYBMEHffReVa0kt12Csj_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWzHnTGzJKVo"
      },
      "source": [
        "Epoch 50:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd8O9lzBJMjN"
      },
      "source": [
        "![Epoch_10](https://drive.google.com/uc?export=view&id=1LBv1ke4APw8Xh3k6kRcbgXunktfm6W_2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj2zDuSPFZSq"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duaXtOVkra69"
      },
      "source": [
        "gifPath = Path(\"./transitions.gif\")\n",
        "# Display 30 images compiled into GIF (nearly 90 epochs)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf1QxVbZM_QN"
      },
      "source": [
        "gifPath2 = Path(\"./Interpolation.gif\")\n",
        "# Cool interpolation gif\n",
        "with open(gifPath2,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e1Y0K5JryOe"
      },
      "source": [
        "# 5. Credits and references:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8SsEeSxr4zQ"
      },
      "source": [
        "* Thanks to diegoalejogm for his public code for all types of GANs. Available [here](https://github.com/diegoalejogm/gans)\n",
        "\n",
        "*   Gan Structure by Garima Nishad. Available [here](https://medium.com/intel-student-ambassadors/mnist-gan-detailed-step-by-step-explanation-implementation-in-code-ecc93b22dc60)\n",
        "*   Interpolation GIF by Nikesh Bajaj\n",
        "\n"
      ]
    }
  ]
}